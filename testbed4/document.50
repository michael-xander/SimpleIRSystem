approximation or a very approximated scene which is denied because typically except planets, asteroids and satellites in space nothing hangs in space. So we have object sitting on a surface you are sitting in a chair now my hand rests on a table on so on. So, if you have one or multiple sources you are bound to have shadows on the platform in which the objects are resting. We will see examples of that later on but you have already seen examples of it. So you have to implement shadows so that is another key part and ray tracing could help in this particular case. So, in real world environment the light rays flow in almost infinite directions. I talked about this sometime back and the some of these light sources are directly from this source and some are reflected from shiny surfaces of the object.
Of course the surface reflectance properties have a very important role to play here. If you have an almost perfect dark or a black object it will not reflect any light of course even if it reflects a small amount that can be considered negligible. Of course when we talk of shiny surfaces like aluminum foil or silver or it can be gold that reflects almost the entire part of the light which is a special case of that also is a mirror surface. But there are lots of other shiny surfaces. You can produce a shiny surface using a glossy paint so some parts of the surface may reflect more and some reflect less, it all depends upon the surface reflectance properties as to what extent it will reflect and of course in what direction.
I discussed about the real world environment, there are virtually rays going in almost infinite directions and we have to capture only a small subset of that. And that is impossible to model so we will see what the simplistic assumptions are to generate a scene which appears as close as possible to real world. That is the essence and that is the motivation behind which the computer scientist and computer graphics engineers had
been working to try to come up with sophisticated algorithms may be a little bit complicated not too complex if possible to generate realistic scenes in virtual reality which may appear as close as possible to reality.
It may not appear absolutely real, true because almost everybody given two photographs however realistically one generates by graphic scene and a photograph taken from a digital camera of even a lay man could distinguish between the two but our objective here is not to make scenes which appear too virtual.
Let us say I am talking of cartoon pictures or even some videogames the old traditional ones. Some of the videogames have lot of effects of 3D shadows and good amount of animation and all that but I am talking of reality in terms of education, training, scientific and engineering studies where you need to provide realistic scene whatever you are modeling and give it to visualization such that it appears almost natural and real as possible.
Again I use the word almost and near because I say that we cannot model infinite rays and a fraction of an infinite rays passing through a smaller aperture. You can visualize that is also infinite in some sense so that also cannot be modeled. So what we model is a set of finite amount of rays coming out may be from the source some of them reflected by object inter reflected by other object that is the most difficult problem to simulate or model inter-reflections which causes a particular type of illumination which we will see later on.
But right now we will see that we will consider certain simplistic model and try to create scenes which is almost as real as possible and that is what we are studying computer graphics for. So, coming back to this problem which says why it is a hard problem the problem of illumination and shading as to why it is hard because in a real world environment light rays flow in almost infinite directions some direct from the source and some reflected from shiny surfaces of objects.
(Refer Slide Time 21:17)
A real world image taken using a digital camera will only capture a small subset of these light rays or light energy passing through the small area. So I repeat again, a real world image that is not what you are simulating using computer graphics but the image captured on a snapshot taken using a digital camera will only capture a small subset of these light energy which is again infinite in terms of the number of rays passing through the small area and so we have to make a crude approximation of that area that approximation will be quite close to reality it will not be far away. We have to ensure how close we can go to reality to ensure that scenes look as real as possible.
Hence, to accurately construct a picture of this room say the room in which you are sitting or studying at the room in which this current computer graphics lecture is being recorded and use that to model and reconstruct the picture of this room via computer graphics we have to simulate this illumination process and be able to calculate the shading at each point of each surface in our scene, so you see the difficulty now.
If you look at this room in which are sitting or this room where I am currently delivering this lecture, well there are lots of light sources here which are illuminating light in all direction of course most of them coming towards the object and when we talk of objects here the tables and chairs in which we are sitting here or of the objects of the computer system which you are working or the body parts, the cloths fabrics which were varying each will of them will be receiving light in virtually infinite directions. They will be reflecting light also in different directions. The inter-reflection rays will also come. They will also be reflected back and so on and that is where you have to model this as accurately as possible.
How is it possible to model infinite amount of rays? You know that there is no way a value which is infinity or a database cannot hold infinite amount of records. We cannot do that, we cannot store infinite amount of rays, but the information about that in a
system we can store as much as possible. We will try to see whether that is the ray by which illumination is modeled or some other approximations are considered and then combine with the VSD algorithms to create virtual reality, visual realism in virtual reality. That means you should able to view reality through computer graphics that is the case. And then we often have an approximated view or often an approximated view is generated using many complex formulations and algorithms. Therefore, we will see how this complex environment is modeled using some complex formulation. So you may not have time to go through all the sources of complex formulation but at least we will discuss algorithms based on some of the basic concepts of illumination and shading and will see how different concepts are combined together to provide real pictures.
(Refer Slide Time 00:23:40)
Of course there has been lot of developments on this illumination and shading. I talked of this term called radio city which we discussed at the end of ray tracing. That is probably one of the best methods so far advances based on those to create visual realism of pictures in virtual reality or computer graphics. Now let us try to understand the process of illumination which involves the surface normal source and viewer directions. And we will also see why these three vectors are the most important key parameters in trying to obtain the illumination of a particular surface.
In this case what I have taken is the upper part of a spherical surface it could be also be a cone, it does not matter and I am interested to find out the illumination at this point O, you can consider it to be a small planar patch or a single pixel. Let us say you have sort a ray from a certain pixel (x, y) from the projection plane towards this object and that pixel ray has struck the curved surface or solid object whatever the case may be at that point (X, Y, Z) which is labeled as O in this figure. We will go back to this figure so there is a small planar patch a polygon there we can assume a small polygon or a single point and that point will have a surface normal n. We can actually compute a surface normal n for
any curved surface at any point (X, Y, Z) or even if you are approximately using a planar patch.
As you know how to do that using, we have seen about wireframe diagrams, sweep representations how to approximate curved surfaces with the help of small polygonal triangular or a quadrilateral planar patches. That is what it is. We are talking about this point O, a small area around this and we want to illuminate that area and calculate the intensity of that point when viewed from a certain direction. So n is the surface normal of that, S is the light source so the light rays are coming from S towards the object O and V represents the viewer directions, V represents the view direction. All these are with respect to the point O which is on the surface, it is a curved surface.
Now what are these two angles? These are very important. I have marked two angles pie and theta. Theta can be visualized as an angle between N and S vectors. I repeat; what is N? N is the surface normal which is retained here, S is the source direction of course the direction of the arrow could be reversed to a point towards the vector pointing towards the resource direction. Although this arrow marks the direction of the light source which are falling on the object surface from S, but you can reverse the arrow direction and say that this is my S direction from O towards S so that this was direction and V of course is pointing towards the viewer direction. So theta is the angle between the surface normal N and the source direction S.
I repeat again, the surface normal and source and theta is the angle between N and S. What is pie? It is the angle between the surface normal N and viewer direction V is the viewer direction. You can have that viewer direction to be arbitrary, source also could be arbitrary, N of course depends upon the properties of the surface objects structure. Now, you must visualize this figure in 3D. This is a very careful observation although it is not mentioned in this slide that is figure is in 3D. What it basically means is S, N and V may not lie on a plane, this is a very interest fact.
Remember, if you take any two vectors you can form a plane consisting of those two vectors, there is absolutely no problem. Any two vectors in 3D space you can actually find out the plane on which these two vectors are aligned. That is absolutely not a problem. Now what about a third vector? It may or may not lie in a plane. In fact you should now visualize that this V does not lie in the plane in general.