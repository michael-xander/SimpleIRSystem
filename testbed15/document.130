San Diego, CA, April 15, 2008 -- UC San Diego computer scientists have created a fog and smoke machine for computer graphics that cuts the computational cost of making realistic smoky and foggy 3-D images, such as beams of light from a lighthouse piercing thick fog.
By cutting the computing cost for creating highly realistic imagery from scratch, the UCSD computer scientists are helping to pull cutting edge graphics techniques out of research labs and into movies and eventually video games and beyond. The findings are being presented this week at Europe’s premier computer graphics conference, Eurographics 2008 in Crete, Greece on April 17.
This new work is part of a shift in the computer graphics, film, animation and video game industries toward greater realism through the use of “ray tracing algorithms.” Much of the realism in ray tracing technologies comes from calculating how the light in computer generated images would behave if it were set loose in the real world and followed the laws of nature.
At the heart of the new UCSD advance are computationally slimmed “photon mapping” algorithms, which are a subset of the ray tracing algorithms. The computer scientists found a way to collect all of the pertinent lighting information in computer generated scenes at once, which made the new photon mapping approach more lightweight than conventional photon mapping. This technique is especially good for creating smoky, foggy or cloudy scenes and producing images that do not have much unwanted visual noise.
“We took an algorithm that is already great and made it more efficient,” said Wojciech Jarosz, the first author on the new Eurographics paper and a Ph.D. candidate from the Department of Computer Science and Engineering at UCSD’s Jacobs School of Engineering.
This approach is an improvement upon the Academy Award winning photon mapping technique first developed by UCSD computer science professor Henrik Wann Jensen during his doctoral studies. Jensen is a co-author on this new Eurographics paper, along with UCSD computer science professor Matthias Zwicker. 
Antelope Canyon
The above picture from Antelope Canyon Navajo Tribal Park provides a real life example of the kinds of scenes that the new research can capture in a computationally efficient manner. The interplay between the dust in the air and the light pouring down from above creates the same smoky ambiance that Wojciech Jarosz creates in his cutting edge computer graphics research at UCSD’s Jacobs School of Engineering.
To date, ray tracing algorithms are primarily used in settings where ultimate realism is required and where heavy computation can be tolerated – such as offline environments that do not require real-time image rendering. An ice-cube-filled drink in the animated movie Final Fantasy is one example of photon mapping in the movies.
Computational constraints, however, have limited the use of photon mapping and other ray tracing approaches in places where speed and lightweight computation are crucial – such as video games. These domains have embraced an approach called rasterization, which is faster, but unable to easily simulate advanced lighting effects.
The new photon mapping approach from UCSD, and related advances, are poised to increase the reach of ray tracing algorithms – perhaps even into the domain of 3-D animation software for the general public and video games. The Larrabee chip that Intel is working on is just one indication that ray tracing technologies may play an increasing important role in consumer oriented graphics of the future.
Computerized Fog Costs 

Much of the richness in images created with photon mapping algorithms comes from precise accounting for the amount of light is in a scene and where that light is. Photon mapping algorithms provide a way to follow the light around the scene, as it bounces off various objects and lands on other objects. Photon mapping can also determine how light will interact with fog, smoke or other “participating media” that absorb, reflect and scatter some portion of the light – a task that has been traditionally quite computationally costly to perform because it requires sampling the light at many locations in order to make sure that nearly all the light is accounted for.
“Instead of computing the light at thousands of discrete points along the ray between the camera and the object, which is the conventional approach, we compute the lighting along the whole length of the ray all at once,” said Jarosz.
Photon mapping comparison image from UCSD
The same scene. The same image rendering time. Very different results. The noisy and pixilated image on the left  was created with the conventional “ray marching” photon mapping technique while the images on the right was created using the new “beam estimate” approach to photon mapping that is computationally more efficient.
To Movies, Then Milk 
This more efficient approach to photon mapping could be extended well beyond foggy and smoky scenes, because many materials, including skin, milk and plants, behave like fog or smoke, but on a more limited basis.
“Most natural materials behave like really dense fog because light penetrates them to a limited extent, so this work has a lot of potential future applications,” said Jensen, who published work in 2007 at SIGGRAPH on a graphics model capable of generating realistic milk images based on the fat and protein content. This research is pushing the field of computer graphics into the realms of diagnostic medicine, food safety and atmospheric science.
While photon mapping and other ray tracing algorithms that more closely mimic the natural world are making their way into movie special effects and animated films, Jarosz does not expect movies and video games to strictly follow the laws of nature.
“In live action movies, the lighting is incredibly controlled. If a character walks into a shadow, they will add light to the face even if you would never get that kind of light in a real shadow. The composition on the screen must tell the story and not distract the viewer. Realism doesn’t always matter. It’s the movies.”
Eurographics 2008 Paper: “The Beam Radiance Estimate for Volumetric Photon Mapping,”
